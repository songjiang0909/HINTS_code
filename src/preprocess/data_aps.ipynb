{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import pickle as pkl\n",
    "import collections\n",
    "import re\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRMATERIALS\n",
      "357\n",
      "357\n",
      "PRSTPER\n",
      "368\n",
      "368\n",
      "PRD\n",
      "80785\n",
      "80785\n",
      "PR\n",
      "47937\n",
      "47937\n",
      "PRA\n",
      "76006\n",
      "76006\n",
      "PRX\n",
      "1040\n",
      "1040\n",
      "PRAB\n",
      "422\n",
      "422\n",
      "PRC\n",
      "37193\n",
      "37193\n",
      "PRFLUIDS\n",
      "731\n",
      "731\n",
      "PRSTAB\n",
      "2356\n",
      "2356\n",
      "PRAPPLIED\n",
      "1012\n",
      "1012\n",
      "PRPER\n",
      "179\n",
      "179\n",
      "PRI\n",
      "1469\n",
      "1469\n",
      "RMP\n",
      "3299\n",
      "3299\n",
      "PRL\n",
      "117052\n",
      "117052\n",
      "PRE\n",
      "55668\n",
      "55668\n",
      "PRB\n",
      "182183\n",
      "182183\n",
      "608057\n",
      "916\n"
     ]
    }
   ],
   "source": [
    "author_set = set()\n",
    "venue_set = set()\n",
    "paper_id_title = {}\n",
    "paper_title_id = {}\n",
    "date_set = set()\n",
    "cnt = 0\n",
    "total = 0\n",
    "zero_path  =     \"/home/songjiang/PycharmProjects/HINTS/HINTS/aps/metadata/\"\n",
    "zero_folder = os.listdir(zero_path)\n",
    "for journal in zero_folder:\n",
    "    journal_total = 0\n",
    "    journal_count = 0\n",
    "    path = zero_path+journal+'/'\n",
    "    files= os.listdir(path) \n",
    "    for file in files:\n",
    "        total = total + 1\n",
    "        new_path = path+str(file)\n",
    "        paper_set = os.listdir(new_path)\n",
    "        for paper_file in paper_set: \n",
    "            with open(new_path+'/'+paper_file) as f:\n",
    "                paper = f.readlines()\n",
    "            paper = json.loads(paper[0]) \n",
    "            try:\n",
    "                paper_id = paper['id'] #str\n",
    "                paper_id_title[paper_id] = paper['title']['value']\n",
    "                paper_title_id[paper['title']['value']] = paper_id\n",
    "                authors_list = paper['authors']\n",
    "                for author in authors_list:\n",
    "                    author_set.add(author['name'])  #str\n",
    "                venue_set.add(paper['journal']['name'])#str\n",
    "                date_set.add(paper['date'].split('-')[0])\n",
    "                journal_total = journal_total + 1\n",
    "                journal_count = journal_count + 1 \n",
    "                cnt = cnt + 1\n",
    "            except:\n",
    "                label = 1\n",
    "                pass\n",
    "    print (journal)\n",
    "    print (journal_total)\n",
    "    print (journal_count)\n",
    "print (cnt)\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list = list(author_set)\n",
    "author_index = list(range(len(author_list)))\n",
    "author_id = [index+2000000 for index in author_index]\n",
    "author_id_name = dict(zip(author_id, author_list))\n",
    "author_name_id = dict(zip(author_list, author_id))\n",
    "\n",
    "venue_list = list(venue_set)\n",
    "venue_index = list(range(len(venue_list)))\n",
    "venue_id = [index+1000000 for index in venue_index]\n",
    "venue_id_name = dict(zip(venue_id,venue_list))\n",
    "venue_name_id = dict(zip(venue_list,venue_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [v for k,v in paper_id_title.items()]\n",
    "titles_key = [k for k,v in paper_id_title.items()]\n",
    "titles_index = list(range(len(titles)))\n",
    "paper_id = [index+3000000 for index in titles_index]\n",
    "paper_id_title = dict(zip(paper_id,titles))\n",
    "paper_title_id = dict(zip(titles,paper_id))\n",
    "paper_id_key = dict(zip(paper_id,titles_key))\n",
    "paper_key_id = dict(zip(titles_key,paper_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "titles = [v for k,v in paper_id_title.items()]\n",
    "with open ('../aps/keywords/titles_test.txt','w') as f:\n",
    "    for title in titles:\n",
    "        cnt = cnt + 1\n",
    "        f.write(title)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../aps/keywords/segmentation.txt') as f:\n",
    "    keywords = f.readlines()\n",
    "keywords_set = set()\n",
    "for segement in keywords:\n",
    "    p1 = re.compile(r'<phrase>(.*?)</phrase>', re.S)\n",
    "    result = (re.findall(p1, segement))\n",
    "    for term in result:\n",
    "        keywords_set.add(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list = list(keywords_set)\n",
    "keywords_index = list(range(len(keywords_list)))\n",
    "keyword_id = [index for index in keywords_index]\n",
    "keyword_id_name = dict(zip(keyword_id, keywords_list))\n",
    "keyword_name_id = dict(zip(keywords_list, keyword_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'paper_id_title':paper_id_title,\n",
    "               'paper_title_id':paper_title_id,\n",
    "               'author_id_name':author_id_name,\n",
    "               'author_name_id':author_name_id,\n",
    "               'venue_id_name':venue_id_name,\n",
    "              'venue_name_id':venue_name_id,\n",
    "              'keywords_id_name':keyword_id_name,\n",
    "              'keywords_name_id':keyword_name_id,\n",
    "              'keywords_set':keywords_set,\n",
    "              'venue_set':venue_set,\n",
    "              'paper_id_key':paper_id_key,\n",
    "              'paper_key_id':paper_key_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../aps/index_item_map.pkl', 'wb') as f:\n",
    "    pkl.dump(data,f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = pd.read_csv('../aps/citation/aps-dataset-citations-2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../aps/index_item_map.pkl', 'rb') as f:\n",
    "    data_map = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id_title = data_map['paper_id_title']\n",
    "author_id_name = data_map['author_id_name']\n",
    "venue_id_name = data_map['venue_id_name']\n",
    "keywords_id_name = data_map['keywords_id_name']\n",
    "paper_title_id = data_map['paper_title_id']\n",
    "author_name_id = data_map['author_name_id']\n",
    "venue_name_id = data_map['venue_name_id']\n",
    "keywords_name_id = data_map['keywords_name_id']\n",
    "keywords_set = data_map['keywords_set']\n",
    "venue_set = data_map['venue_set']\n",
    "paper_id_key = data_map['paper_id_key']\n",
    "paper_key_id = data_map['paper_key_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2/17 [00:00<00:02,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRMATERIALS\n",
      "357\n",
      "357\n",
      "PRSTPER\n",
      "368\n",
      "368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 3/17 [00:49<03:28, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRD\n",
      "80785\n",
      "80785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 4/17 [01:15<03:56, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR\n",
      "47937\n",
      "47937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 5/17 [01:59<05:12, 26.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRA\n",
      "76006\n",
      "76006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 6/17 [02:00<03:22, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRX\n",
      "1040\n",
      "1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 7/17 [02:00<02:09, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRAB\n",
      "422\n",
      "422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 8/17 [02:26<02:30, 16.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRC\n",
      "37193\n",
      "37193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 9/17 [02:26<01:34, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRFLUIDS\n",
      "731\n",
      "731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 10/17 [02:27<01:00,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRSTAB\n",
      "2356\n",
      "2356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 12/17 [02:28<00:22,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRAPPLIED\n",
      "1012\n",
      "1012\n",
      "PRPER\n",
      "179\n",
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 13/17 [02:29<00:13,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRI\n",
      "1469\n",
      "1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 14/17 [02:31<00:08,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMP\n",
      "3299\n",
      "3299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 15/17 [03:41<00:46, 23.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRL\n",
      "117052\n",
      "117052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 16/17 [04:11<00:25, 25.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE\n",
      "55668\n",
      "55668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 17/17 [06:00<00:00, 50.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRB\n",
      "182183\n",
      "182183\n",
      "608057\n",
      "916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "document = open(\"../aps/part_pairs.csv\",'w')\n",
    "author_set = set()\n",
    "venue_set = set()\n",
    "date_set = set()\n",
    "cnt = 0\n",
    "total = 0\n",
    "zero_path  =     \"/home/songjiang/PycharmProjects/HINTS/HINTS/aps/metadata/\"\n",
    "zero_folder = os.listdir(zero_path)\n",
    "for journal in tqdm(zero_folder):\n",
    "    journal_total = 0\n",
    "    journal_count = 0\n",
    "    path = zero_path+journal+'/'\n",
    "    files= os.listdir(path) \n",
    "    for file in files:\n",
    "        total = total + 1\n",
    "        new_path = path+str(file)\n",
    "        paper_set = os.listdir(new_path)\n",
    "        for paper_file in paper_set: \n",
    "            with open(new_path+'/'+paper_file) as f:\n",
    "                paper = f.readlines()\n",
    "            paper = json.loads(paper[0]) \n",
    "            towirite = []\n",
    "    #         total = total + 1\n",
    "            try:\n",
    "                paper_id = paper['id'] #str\n",
    "#                 print (paper_id)\n",
    "                paper_id = paper_key_id[str(paper_id)]\n",
    "                authors_list = paper['authors']  #str\n",
    "                venue_id = venue_name_id[paper['journal']['name']]#str\n",
    "                towirite.append(str(paper_id)+\",\"+str(venue_id)+\",\"+\"P1V\")\n",
    "                year = (paper['date'].split('-')[0])\n",
    "                towirite.append(str(paper_id)+\",\"+str(year)+\",\"+\"P1Y\")\n",
    "                for author in authors_list:\n",
    "                    towirite.append(str(paper_id) +',' +str(author_name_id[author['name']])+','+'P1A' )\n",
    "                journal_total = journal_total + 1\n",
    "                journal_count = journal_count + 1 \n",
    "                cnt = cnt + 1\n",
    "                document.writelines([\"%s\\n\" % item  for item in towirite])\n",
    "            except:\n",
    "                label = 1\n",
    "    print (journal)\n",
    "    print (journal_total)\n",
    "    print (journal_count)\n",
    "print (cnt)\n",
    "print (total)\n",
    "document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pair = pd.read_csv('../aps/part_pairs.csv',names=['P','O','type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = citations.rename(columns={\"citing_doi\": \"P\", \"cited_doi\": \"O\"})\n",
    "citations['type'] ='P1P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = set([v for k,v  in paper_id_key.items()])\n",
    "citations_P = citations['P'].tolist()\n",
    "citations_O = citations['O'].tolist()\n",
    "left_id = set()\n",
    "right_id = set()\n",
    "for i in range(len(citations_P)):\n",
    "    if citations_P[i] in keys:\n",
    "        left_id.add(i)\n",
    "    if citations_O[i] in keys:\n",
    "        right_id.add(i)\n",
    "keep_ids = (list(left_id & right_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = (citations.iloc[keep_ids,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_trans(x):\n",
    "    return paper_key_id[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songjiang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/songjiang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "citations['P'] = citations['P'].apply(id_trans)\n",
    "citations['O'] = citations['O'].apply(id_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pair  = pd.concat([citations,full_pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616316"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_list = []\n",
    "with open('../aps/keywords/segmentation.txt') as f:\n",
    "    keywords = f.readlines()\n",
    "cnt = 0\n",
    "for segement in keywords:\n",
    "    terms = []\n",
    "    p1 = re.compile(r'<phrase>(.*?)</phrase>', re.S)\n",
    "    result = (re.findall(p1, segement))\n",
    "    for term in result:\n",
    "        terms.append(term)\n",
    "    keywords_list.append(terms)\n",
    "    cnt = cnt + 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1K_left = [k for k,v in paper_id_title.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_set = ( 'math', 'Math', 'MathML', 'mn', 'mn', 'mn', 'mn', 'math','NH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = []\n",
    "right = []\n",
    "for i in range(len(P1K_left)):\n",
    "    keywords = keywords_list[i]\n",
    "    for kw in keywords:\n",
    "        if kw not in delete_set:\n",
    "            left.append(P1K_left[i])\n",
    "            right.append(keywords_name_id[kw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "PK_df = pd.DataFrame(list(zip(left, right)), columns =['P', 'O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "PK_df['type'] = 'P1K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pair  = pd.concat([full_pair,PK_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pair.to_csv('../aps/whole_graph.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
