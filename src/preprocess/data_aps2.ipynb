{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import scipy.sparse as sp\n",
    "import pickle as pkl\n",
    "import collections \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../aps/index_item_map.pkl', 'rb') as f:\n",
    "    data_map = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id_title = data_map['paper_id_title']\n",
    "author_id_name = data_map['author_id_name']\n",
    "venue_id_name = data_map['venue_id_name']\n",
    "keywords_id_name = data_map['keywords_id_name']\n",
    "paper_title_id = data_map['paper_title_id']\n",
    "author_name_id = data_map['author_name_id']\n",
    "venue_name_id = data_map['venue_name_id']\n",
    "keywords_name_id = data_map['keywords_name_id']\n",
    "keywords_set = data_map['keywords_set']\n",
    "venue_set = data_map['venue_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ids = set(paper_id_title.keys())\n",
    "author_ids = set(author_id_name.keys())\n",
    "venue_ids = set(venue_id_name.keys())\n",
    "keywords_ids = set(keywords_id_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pair = pd.read_csv('../aps/whole_graph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_P1P = full_pair[full_pair.type=='P1P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "for year in range(1990,2018):\n",
    "    paper_list_2001 = full_pair[(full_pair.O==year)&(full_pair.type=='P1Y')]['P']\n",
    "    citation_2001 = pd.merge(paper_list_2001,full_P1P)\n",
    "    citation_2001 = citation_2001.groupby('O').count().reset_index()[['O','type']]\n",
    "    citation_2001.to_csv('../aps/citation_'+str(year)+\".csv\",index=None)\n",
    "    print (year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative(df):\n",
    "    colsn = list(df.columns)\n",
    "    cols = df.shape[1]\n",
    "    for i in range(2,cols):\n",
    "        df[colsn[i]] = df[colsn[i]] + df[colsn[i-1]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n"
     ]
    }
   ],
   "source": [
    "for year in range(1995,2006):\n",
    "    paper_list_2000 = full_pair[(full_pair.O==year)&(full_pair.type=='P1Y')]['P']\n",
    "    for i in range(1,13):\n",
    "        citation_year = pd.read_csv('../aps/citation_'+str(year+i)+\".csv\")\n",
    "        citation_year = citation_year.rename(columns={\"O\": \"P\",\"type\":(\"citation_\"+str(year+i))})\n",
    "        paper_list_2000 = pd.merge(paper_list_2000,citation_year,left_on='P',right_on='P',how='left')\n",
    "    paper_list_2000 = paper_list_2000.fillna(0)\n",
    "    if year == 2000:\n",
    "        pp2000 = paper_list_2000\n",
    "    if year == 2005:\n",
    "        pp2005 = paper_list_2000\n",
    "    paper_list_2000.to_csv('../aps_for_intro/original_labels'+str(year)+'.txt',index=None,header=False)\n",
    "      \n",
    "    cols = paper_list_2000.columns\n",
    "    paper_list_2000_log = pd.DataFrame({\"P\":paper_list_2000[\"P\"],cols[1]:0,cols[2]:0,cols[3]:0,cols[4]:0,cols[5]:0})\n",
    "    paper_list_2000_log.iloc[:,1:] = np.log(paper_list_2000.iloc[:,1:]+1)\n",
    "    paper_list_2000_log.to_csv('../aps/log_labels'+str(year)+'.txt',index=None)\n",
    "        \n",
    "    paper_list_2000_cumu = cumulative(paper_list_2000)\n",
    "    paper_list_2000_cumu.to_csv('../aps/cumulative_labels'+str(year)+'.txt',index=None,header=False)\n",
    "\n",
    "    paper_list_2000_cumu_log = pd.DataFrame({\"P\":paper_list_2000[\"P\"],cols[1]:0,cols[2]:0,cols[3]:0,cols[4]:0,cols[5]:0})\n",
    "    paper_list_2000_cumu_log.iloc[:,1:] = np.log(paper_list_2000_cumu.iloc[:,1:]+1)\n",
    "    paper_list_2000_cumu_log.to_csv('../aps/cumulative_log_labels'+str(year)+'.txt',index=None)\n",
    "    print (year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# pd.read_csv('../aps/cumulative_log_labels'+str(year)+'.txt').iloc[:, 1:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_element(x):\n",
    "    if int(x) in paper_ids:\n",
    "        return np.array([1,0,0,0])\n",
    "    elif int(x) in author_ids:\n",
    "        return np.array([0,1,0,0])\n",
    "    elif int(x) in venue_ids:\n",
    "        return np.array([0,0,1,0])\n",
    "    elif int(x) in keywords_ids:\n",
    "        return np.array([0,0,0,1])\n",
    "    else:\n",
    "        print (x)\n",
    "def create_feature(array):\n",
    "    return np.array( [ feature_element(num)   for num in array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songjiang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69164\n",
      "2.258089542388916\n",
      "1991\n",
      "73648\n",
      "2.1792190074920654\n",
      "1992\n",
      "80899\n",
      "2.250282049179077\n",
      "1993\n",
      "90371\n",
      "2.386385440826416\n",
      "1994\n",
      "95389\n",
      "2.4106216430664062\n",
      "1995\n",
      "102179\n",
      "2.552769660949707\n",
      "1996\n",
      "105188\n",
      "2.4546873569488525\n",
      "1997\n",
      "105211\n",
      "2.4426045417785645\n",
      "1998\n",
      "115242\n",
      "2.630056619644165\n",
      "1999\n",
      "119204\n",
      "2.58478045463562\n",
      "2000\n",
      "126152\n",
      "2.773040533065796\n",
      "2001\n",
      "130274\n",
      "2.8419830799102783\n",
      "2002\n",
      "138309\n",
      "2.9367306232452393\n",
      "2003\n",
      "137805\n",
      "2.913489580154419\n",
      "2004\n",
      "149351\n",
      "3.0425236225128174\n"
     ]
    }
   ],
   "source": [
    "for year in range(1990,2005):\n",
    "    print (year)\n",
    "    t = time.time()\n",
    "    P1Y_2000 = full_pair[(full_pair.type=='P1Y')]\n",
    "    P1Y_2000['O'] =P1Y_2000['O'].astype('int')\n",
    "#     P1Y_2000 = P1Y_2000[(P1Y_2000.O<=year)]\n",
    "    P1Y_2000 = P1Y_2000[(P1Y_2000.O==year)]\n",
    "    all_paper_2000 = pd.DataFrame({\"P\":list(set(P1Y_2000['P']))})\n",
    "    full_pair_2000 = pd.merge(all_paper_2000,full_pair,how=\"left\")\n",
    "    full_pair_2000[full_pair_2000.type!='P1Y']\n",
    "    idx_2000 = np.array(list(set(pd.concat([full_pair_2000['P'],full_pair_2000['O']]))))\n",
    "    id_item_2000 = {i:j for i,j in enumerate(idx_2000)}\n",
    "    item_id_2000 = {j:i for i,j in enumerate(idx_2000)}\n",
    "    feature_2000 = create_feature(idx_2000)\n",
    "    print (idx_2000.shape[0])\n",
    "\n",
    "    P1P_pair_2000 = full_pair_2000[full_pair_2000.type=='P1P']\n",
    "    row = np.array([item_id_2000[item] for item in list(P1P_pair_2000['P'])])\n",
    "    col = np.array([item_id_2000[item] for item in list(P1P_pair_2000['O'])])\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_P1P_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    P1A_pair_2000 = full_pair_2000[full_pair_2000.type=='P1A']\n",
    "    row = np.array([item_id_2000[item] for item in list(P1A_pair_2000['P'])])\n",
    "    col = np.array([item_id_2000[item] for item in list(P1A_pair_2000['O'])])\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_P1A_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    P1V_pair_2000 = full_pair_2000[full_pair_2000.type=='P1V']\n",
    "    row = np.array([item_id_2000[item] for item in list(P1V_pair_2000['P'])])\n",
    "    col = np.array([item_id_2000[item] for item in list(P1V_pair_2000['O'])])\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_P1V_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    P1K_pair_2000 = full_pair_2000[full_pair_2000.type=='P1K']\n",
    "    row = np.array([item_id_2000[item] for item in list(P1K_pair_2000['P'])])\n",
    "    col = np.array([item_id_2000[item] for item in list(P1K_pair_2000['O'])])\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_P1K_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    row = np.array(range(len(idx_2000)))\n",
    "    col =  np.array(range(len(idx_2000)))\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_self_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    graph = {'adj':[adj_P1P_2000,adj_P1A_2000,adj_P1V_2000,adj_P1K_2000,adj_self_2000],\n",
    "                     'feature':feature_2000,\n",
    "                     ' idx':idx_2000,\n",
    "                     'id_item':id_item_2000,\n",
    "                     'item_id':item_id_2000}\n",
    "    with open('../aps/individual_graph_'+str(year)+'.pkl','wb') as f:\n",
    "        pkl.dump(graph,f,0)\n",
    "    print (time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songjiang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913797\n",
      "22.430230140686035\n"
     ]
    }
   ],
   "source": [
    "for year in range(2012,2013):\n",
    "    print (year)\n",
    "    t = time.time()\n",
    "    P1Y_2000 = full_pair[(full_pair.type=='P1Y')]\n",
    "    P1Y_2000['O'] =P1Y_2000['O'].astype('int')\n",
    "    P1Y_2000 = P1Y_2000[(P1Y_2000.O<=year)]\n",
    "#     P1Y_2000 = P1Y_2000[(P1Y_2000.O==year)]\n",
    "    all_paper_2000 = pd.DataFrame({\"P\":list(set(P1Y_2000['P']))})\n",
    "    full_pair_2000 = pd.merge(all_paper_2000,full_pair,how=\"left\")\n",
    "    full_pair_2000[full_pair_2000.type!='P1Y']\n",
    "    idx_2000 = np.array(list(set(pd.concat([full_pair_2000['P'],full_pair_2000['O']]))))\n",
    "    id_item_2000 = {i:j for i,j in enumerate(idx_2000)}\n",
    "    item_id_2000 = {j:i for i,j in enumerate(idx_2000)}\n",
    "    feature_2000 = create_feature(idx_2000)\n",
    "    print (idx_2000.shape[0])\n",
    "\n",
    "    P1P_pair_2000 = full_pair_2000[full_pair_2000.type=='P1P']\n",
    "    row = np.array([item_id_2000[item] for item in list(P1P_pair_2000['P'])])\n",
    "    col = np.array([item_id_2000[item] for item in list(P1P_pair_2000['O'])])\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_P1P_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    P1A_pair_2000 = full_pair_2000[full_pair_2000.type=='P1A']\n",
    "    row = np.array([item_id_2000[item] for item in list(P1A_pair_2000['P'])])\n",
    "    col = np.array([item_id_2000[item] for item in list(P1A_pair_2000['O'])])\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_P1A_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    P1V_pair_2000 = full_pair_2000[full_pair_2000.type=='P1V']\n",
    "    row = np.array([item_id_2000[item] for item in list(P1V_pair_2000['P'])])\n",
    "    col = np.array([item_id_2000[item] for item in list(P1V_pair_2000['O'])])\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_P1V_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    P1K_pair_2000 = full_pair_2000[full_pair_2000.type=='P1K']\n",
    "    row = np.array([item_id_2000[item] for item in list(P1K_pair_2000['P'])])\n",
    "    col = np.array([item_id_2000[item] for item in list(P1K_pair_2000['O'])])\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_P1K_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    row = np.array(range(len(idx_2000)))\n",
    "    col =  np.array(range(len(idx_2000)))\n",
    "    data = np.ones(row.shape[0])\n",
    "    adj_self_2000 = sp.csr_matrix((data,(row,col)),shape=(idx_2000.shape[0],idx_2000.shape[0]))\n",
    "\n",
    "    graph = {'adj':[adj_P1P_2000,adj_P1A_2000,adj_P1V_2000,adj_P1K_2000,adj_self_2000],\n",
    "                     'feature':feature_2000,\n",
    "                     ' idx':idx_2000,\n",
    "                     'id_item':id_item_2000,\n",
    "                     'item_id':item_id_2000}\n",
    "    with open('../aps/all_graph_'+str(year)+'.pkl','wb') as f:\n",
    "        pkl.dump(graph,f,0)\n",
    "    print (time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
