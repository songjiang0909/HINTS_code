{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import pickle as pkl\n",
    "import collections \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/dblp.v11/dblp_papers_v11.txt','r')\n",
    "all_data = f.readlines()\n",
    "len(all_data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construct id&description map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# cnt = 0\n",
    "# paper_id_title = {}\n",
    "# author_id_name = {}\n",
    "# venue_set = set()\n",
    "# venue_id_name = {}\n",
    "# keywords_set = set()\n",
    "# t = time.time()\n",
    "# lable = 0\n",
    "# for paper in all_data:\n",
    "#     try:\n",
    "#         p = json.loads(paper)\n",
    "#         paper_id = p['id']\n",
    "#         paper_title = p['title']\n",
    "#         author_list = p['authors']\n",
    "#         for author in author_list:\n",
    "#             author_id_name[author['id']] = author['name']\n",
    "#         paper_id_title[paper_id] = paper_title\n",
    "#         venue_set.add(p['venue']['raw'])\n",
    "#         fos_list = p['fos']\n",
    "#         for fos in fos_list:\n",
    "#             keywords_set.add(fos['name'])\n",
    "#         paper_id_title[paper_id] = paper_title\n",
    "#         venue_id_name[p['venue']['id']] = p['venue']['raw']\n",
    "#         cnt = cnt + 1\n",
    "#     except:\n",
    "#         lable = 1\n",
    "#         pass\n",
    "#     if cnt %500000 == 0:\n",
    "#         print (cnt)\n",
    "#         time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = list(keywords_set)\n",
    "# keyword_id = list(range(len(keywords)))\n",
    "# keywords_id_name = dict(zip(keyword_id, keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_title_id = {v: k for k, v in paper_id_title.items()}\n",
    "# author_name_id = {v: k for k, v in author_id_name.items()}\n",
    "# venue_name_id = {v: k for k, v in venue_id_name.items()}\n",
    "# keywords_name_id = {v: k for k, v in keywords_id_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\"paper_id_title\":paper_id_title,\n",
    "#                \"author_id_name\" :author_id_name,\n",
    "#                \"venue_id_name\" :venue_id_name,\n",
    "#               'keywords_id_name':keywords_id_name,\n",
    "#               'paper_title_id': paper_title_id,\n",
    "#               'author_name_id':author_name_id,\n",
    "#               'venue_name_id':venue_name_id,\n",
    "#               'keywords_name_id':keywords_name_id,\n",
    "#                \"keywords_set\" : keywords_set,\n",
    "#                \"venue_set\":venue_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/index_item_map.pkl', 'wb') as f:\n",
    "#     pkl.dump(data, f,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### table for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/index_item_map.pkl', 'rb') as f:\n",
    "    data_map = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id_title = data_map['paper_id_title']\n",
    "author_id_name = data_map['author_id_name']\n",
    "venue_id_name = data_map['venue_id_name']\n",
    "keywords_id_name = data_map['keywords_id_name']\n",
    "paper_title_id = data_map['paper_title_id']\n",
    "author_name_id = data_map['author_name_id']\n",
    "venue_name_id = data_map['venue_name_id']\n",
    "keywords_name_id = data_map['keywords_name_id']\n",
    "keywords_set = data_map['keywords_set']\n",
    "venue_set = data_map['venue_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 532229/4107340 [00:37<04:09, 14321.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt:500000 needs 37.05117225646973 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1071151/4107340 [01:20<04:18, 11760.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt:1000000 needs 79.95236849784851 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1615028/4107340 [02:02<03:11, 13042.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt:1500000 needs 122.62412595748901 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2155183/4107340 [02:46<02:51, 11409.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt:2000000 needs 166.003892660141 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 2691121/4107340 [03:30<01:57, 12015.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt:2500000 needs 210.27329444885254 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3214976/4107340 [04:08<01:08, 13060.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt:3000000 needs 248.08551335334778 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 3735382/4107340 [04:48<00:29, 12500.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt:3500000 needs 288.0053074359894 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4107340/4107340 [05:10<00:00, 13207.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2994084"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f = open('../data/whole_list.txt','w')\n",
    "# cnt = 0\n",
    "# label = 0\n",
    "# full_paper = set()\n",
    "# t = time.time()\n",
    "\n",
    "# for ix in tqdm(range(len(all_data))):\n",
    "#     paper = all_data[ix]\n",
    "#     try:\n",
    "#         content = []\n",
    "#         p = json.loads(paper)\n",
    "#         pid = p['id']\n",
    "#         references = p['references']\n",
    "#         if len(references) == 0:\n",
    "#             continue\n",
    "#         for reference in references:\n",
    "#             content.append(str(pid)+','+str(reference)+','+'P1P')#'P1P'\n",
    "#         authores =  p['authors']\n",
    "#         for author in authores:\n",
    "#             content.append(str(pid)+','+str(author['id'])+','+'P1A')#P1A\n",
    "#         venue = p['venue']['id']\n",
    "#         content.append(str(pid)+','+str(venue)+','+'P1V')#'P1V'\n",
    "#         fos_list = p['fos']\n",
    "#         for fos in fos_list:\n",
    "#             kid = keywords_name_id[fos['name']]\n",
    "#             content.append(str(pid)+','+str(kid)+','+'P1K')#'P1K'\n",
    "#         content.append(str(pid)+','+str(p['year'])+','+'P1Y')#P1Y\n",
    "#         cnt = cnt + 1 \n",
    "#         f.writelines([\"%s\\n\" % item  for item in content])\n",
    "#     except:\n",
    "#         label  = label + 1\n",
    "#     if (cnt+label) % 500000==0:\n",
    "#         print (\"cnt:{} needs {} s\".format(cnt+label,time.time()-t))\n",
    "# f.close()\n",
    "# cnt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pair = pd.read_csv('../data/whole_list.txt',names=['P','O','T'])\n",
    "all_paper_need = set(full_pair['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4789/4107340 [00:00<02:49, 24222.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cnt:0 needs 0.4089512825012207 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 626918/4107340 [00:31<03:07, 18562.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "cnt:500000 needs 32.12847876548767 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1192047/4107340 [01:04<02:45, 17652.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "cnt:1000000 needs 64.58174777030945 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1756298/4107340 [01:36<02:29, 15768.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500000\n",
      "cnt:1500000 needs 96.35419273376465 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2298277/4107340 [02:07<01:41, 17867.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n",
      "cnt:2000000 needs 127.56252408027649 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 2828677/4107340 [02:39<01:24, 15216.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500000\n",
      "cnt:2500000 needs 159.4279088973999 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 3482485/4107340 [03:15<00:35, 17637.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n",
      "cnt:3000000 needs 195.30967116355896 s\n",
      "3000000\n",
      "cnt:3000000 needs 195.30976486206055 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4107340/4107340 [03:46<00:00, 18156.01it/s]\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "label = 0\n",
    "t = time.time()\n",
    "citation_2001 = collections.defaultdict(lambda : 0)\n",
    "citation_2002 = collections.defaultdict(lambda : 0)\n",
    "citation_2003 = collections.defaultdict(lambda : 0)\n",
    "citation_2004 = collections.defaultdict(lambda : 0)\n",
    "citation_2005 = collections.defaultdict(lambda : 0)\n",
    "citation_2006 = collections.defaultdict(lambda : 0)\n",
    "citation_2007  = collections.defaultdict(lambda : 0)\n",
    "citation_2008 = collections.defaultdict(lambda : 0)\n",
    "citation_2009 = collections.defaultdict(lambda : 0)\n",
    "citation_2010 = collections.defaultdict(lambda : 0)\n",
    "citation_2011 = collections.defaultdict(lambda : 0)\n",
    "citation_2012 = collections.defaultdict(lambda : 0)\n",
    "citation_2013 = collections.defaultdict(lambda : 0)\n",
    "citation_2014 = collections.defaultdict(lambda : 0)\n",
    "citation_2015 = collections.defaultdict(lambda : 0)\n",
    "citation_2016 = collections.defaultdict(lambda : 0)\n",
    "citation_2017 = collections.defaultdict(lambda : 0)\n",
    "citation_2018 = collections.defaultdict(lambda : 0)\n",
    "for ix in tqdm(range(len(all_data))):\n",
    "    paper = all_data[ix]\n",
    "    try:\n",
    "        p = json.loads(paper)\n",
    "        year  = p['year']\n",
    "        references = p['references']\n",
    "        if year ==2006:\n",
    "            for reference in references:\n",
    "                citation_2006[reference] = citation_2006[reference] + 1\n",
    "        elif year == 2007:\n",
    "            for reference in references:\n",
    "                citation_2007[reference] = citation_2007[reference] + 1\n",
    "        elif year == 2008:\n",
    "            for reference in references:\n",
    "                citation_2008[reference] = citation_2008[reference] + 1 \n",
    "        elif year == 2009 :\n",
    "            for reference in references:\n",
    "                citation_2009[reference] = citation_2009[reference] + 1\n",
    "        elif year == 2010:\n",
    "            for reference in references:\n",
    "                citation_2010[reference] = citation_2010[reference] + 1\n",
    "        elif year == 2011:\n",
    "            for reference in references:\n",
    "                citation_2011[reference] = citation_2011[reference] + 1\n",
    "        elif year == 2012:\n",
    "            for reference in references:\n",
    "                citation_2012[reference] = citation_2012[reference] + 1\n",
    "        elif year == 2013:\n",
    "            for reference in references:\n",
    "                citation_2013[reference] = citation_2013[reference] + 1\n",
    "        elif year == 2014:\n",
    "            for reference in references:\n",
    "                citation_2014[reference] = citation_2014[reference] + 1\n",
    "        elif year == 2015:\n",
    "            for reference in references:\n",
    "                citation_2015[reference] = citation_2015[reference] + 1\n",
    "        elif year == 2016:\n",
    "            for reference in references:\n",
    "                citation_2016[reference] = citation_2016[reference] + 1\n",
    "        elif year == 2017:\n",
    "            for reference in references:\n",
    "                citation_2017[reference] = citation_2017[reference] + 1\n",
    "        elif year == 2018:\n",
    "            for reference in references:\n",
    "                citation_2018[reference] = citation_2018[reference] + 1\n",
    "        elif year ==2005:\n",
    "            for reference in references:\n",
    "                citation_2005[reference] = citation_2005[reference] + 1\n",
    "        elif year ==2004:\n",
    "            for reference in references:\n",
    "                citation_2004[reference] = citation_2004[reference] + 1\n",
    "        elif year ==2003:\n",
    "            for reference in references:\n",
    "                citation_2003[reference] = citation_2003[reference] + 1\n",
    "        elif year ==2002:\n",
    "            for reference in references:\n",
    "                citation_2002[reference] = citation_2002[reference] + 1\n",
    "        elif year ==2001:\n",
    "            for reference in references:\n",
    "                citation_2001[reference] = citation_2001[reference] + 1\n",
    "        elif year ==2000:\n",
    "            for reference in references:\n",
    "                citation_2000[reference] = citation_2000[reference] + 1\n",
    "        else:\n",
    "            pass\n",
    "        cnt = cnt + 1 \n",
    "    except:\n",
    "        label  = label + 1\n",
    "    if cnt %500000 == 0:\n",
    "        print (cnt)\n",
    "        print (\"cnt:{} needs {} s\".format(cnt,time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cite_2001_df = pd.DataFrame({'P':[int(k) for k,v in citation_2001.items()],'cite_2001_df' : [v for k,v in citation_2001.items()]})\n",
    "cite_2002_df = pd.DataFrame({'P':[int(k) for k,v in citation_2002.items()],'cite_2002_df' : [v for k,v in citation_2002.items()]})\n",
    "cite_2003_df = pd.DataFrame({'P':[int(k) for k,v in citation_2003.items()],'cite_2003_df' : [v for k,v in citation_2003.items()]})\n",
    "cite_2004_df = pd.DataFrame({'P':[int(k) for k,v in citation_2004.items()],'cite_2004_df' : [v for k,v in citation_2004.items()]})\n",
    "cite_2005_df = pd.DataFrame({'P':[int(k) for k,v in citation_2005.items()],'cite_2005_df' : [v for k,v in citation_2005.items()]})\n",
    "cite_2006_df = pd.DataFrame({'P':[int(k) for k,v in citation_2006.items()],'citation_2006' : [v for k,v in citation_2006.items()]})\n",
    "cite_2007_df = pd.DataFrame({'P':[int(k) for k,v in citation_2007.items()],'citation_2007' : [v for k,v in citation_2007.items()]})\n",
    "cite_2008_df = pd.DataFrame({'P':[int(k) for k,v in citation_2008.items()],'citation_2008' : [v for k,v in citation_2008.items()]})\n",
    "cite_2009_df = pd.DataFrame({'P':[int(k) for k,v in citation_2009.items()],'citation_2009' : [v for k,v in citation_2009.items()]})\n",
    "cite_2010_df = pd.DataFrame({'P':[int(k) for k,v in citation_2010.items()],'citation_2010' : [v for k,v in citation_2010.items()]})\n",
    "cite_2011_df = pd.DataFrame({'P':[int(k) for k,v in citation_2011.items()],'citation_2011' : [v for k,v in citation_2011.items()]})\n",
    "cite_2012_df = pd.DataFrame({'P':[int(k) for k,v in citation_2012.items()],'citation_2012' : [v for k,v in citation_2012.items()]})\n",
    "cite_2013_df = pd.DataFrame({'P':[int(k) for k,v in citation_2013.items()],'citation_2013' : [v for k,v in citation_2013.items()]})\n",
    "cite_2014_df = pd.DataFrame({'P':[int(k) for k,v in citation_2014.items()],'citation_2014' : [v for k,v in citation_2014.items()]})\n",
    "cite_2015_df = pd.DataFrame({'P':[int(k) for k,v in citation_2015.items()],'citation_2015' : [v for k,v in citation_2015.items()]})\n",
    "cite_2016_df = pd.DataFrame({'P':[int(k) for k,v in citation_2016.items()],'citation_2016' : [v for k,v in citation_2016.items()]})\n",
    "cite_2017_df = pd.DataFrame({'P':[int(k) for k,v in citation_2017.items()],'citation_2017' : [v for k,v in citation_2017.items()]})\n",
    "cite_2018_df = pd.DataFrame({'P':[int(k) for k,v in citation_2018.items()],'citation_2018' : [v for k,v in citation_2018.items()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20897.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2000_label = full_pair[full_pair.O==2000]\n",
    "P2000_label = pd.DataFrame({'P':list(set(P2000_label['P']))})\n",
    "P2000_label = pd.merge(P2000_label,cite_2001_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2002_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2003_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2004_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2005_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2006_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2007_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2008_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2000_label = pd.merge(P2000_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2000_label = P2000_label.fillna(0)\n",
    "sum(P2000_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24922.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2001_label = full_pair[full_pair.O==2001]\n",
    "P2001_label = pd.DataFrame({'P':list(set(P2001_label['P']))})\n",
    "P2001_label = pd.merge(P2001_label,cite_2002_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2003_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2004_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2005_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2006_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2007_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2008_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2001_label = pd.merge(P2001_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2001_label = P2001_label.fillna(0)\n",
    "sum(P2001_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29527.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2002_label = full_pair[full_pair.O==2002]\n",
    "P2002_label = pd.DataFrame({'P':list(set(P2002_label['P']))})\n",
    "P2002label = pd.merge(P2002_label,cite_2003_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2004_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2005_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2006_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2007_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2008_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2002_label = pd.merge(P2002_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2002_label = P2002_label.fillna(0)\n",
    "sum(P2002_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35322.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2003_label = full_pair[full_pair.O==2003]\n",
    "P2003_label = pd.DataFrame({'P':list(set(P2003_label['P']))})\n",
    "P2003_label = pd.merge(P2003_label,cite_2004_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2005_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2006_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2007_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2008_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2003_label = pd.merge(P2003_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2003_label = P2003_label.fillna(0)\n",
    "sum(P2003_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41642.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2004_label = full_pair[full_pair.O==2004]\n",
    "P2004_label = pd.DataFrame({'P':list(set(P2004_label['P']))})\n",
    "P2004_label = pd.merge(P2004_label,cite_2005_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2006_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2007_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2008_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2004_label = pd.merge(P2004_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2004_label = P2004_label.fillna(0)\n",
    "sum(P2004_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45873.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2005_label = full_pair[full_pair.O==2005]\n",
    "P2005_label = pd.DataFrame({'P':list(set(P2005_label['P']))})\n",
    "P2005_label = pd.merge(P2005_label,cite_2006_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2007_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2008_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2005_label = pd.merge(P2005_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2005_label = P2005_label.fillna(0)\n",
    "sum(P2005_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53360.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2006_label = full_pair[full_pair.O==2006]\n",
    "P2006_label = pd.DataFrame({'P':list(set(P2006_label['P']))})\n",
    "P2006_label = pd.merge(P2006_label,cite_2007_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2008_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2006_label = pd.merge(P2006_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2006_label = P2006_label.fillna(0)\n",
    "sum(P2006_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62129.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2007_label = full_pair[full_pair.O==2007]\n",
    "P2007_label = pd.DataFrame({'P':list(set(P2007_label['P']))})\n",
    "P2007_label = pd.merge(P2007_label,cite_2008_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2007_label = pd.merge(P2007_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2007_label = P2007_label.fillna(0)\n",
    "sum(P2007_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68169.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2008_label = full_pair[full_pair.O==2008]\n",
    "P2008_label = pd.DataFrame({'P':list(set(P2008_label['P']))})\n",
    "P2008_label = pd.merge(P2008_label,cite_2009_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2008_label = pd.merge(P2008_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2008_label = P2008_label.fillna(0)\n",
    "sum(P2008_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84392.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2009_label = full_pair[full_pair.O==2009]\n",
    "P2009_label = pd.DataFrame({'P':list(set(P2009_label['P']))})\n",
    "P2009_label = pd.merge(P2009_label,cite_2010_df,how=\"left\",on=\"P\")\n",
    "P2009_label = pd.merge(P2009_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2009_label = pd.merge(P2009_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2009_label = pd.merge(P2009_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2009_label = pd.merge(P2009_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2009_label = pd.merge(P2009_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2009_label = pd.merge(P2009_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2009_label = pd.merge(P2009_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2009_label = pd.merge(P2009_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2009_label = P2009_label.fillna(0)\n",
    "sum(P2009_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97579.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2010_label = full_pair[full_pair.O==2010]\n",
    "P2010_label = pd.DataFrame({'P':list(set(P2010_label['P']))})\n",
    "P2010_label = pd.merge(P2010_label,cite_2011_df,how=\"left\",on=\"P\")\n",
    "P2010_label = pd.merge(P2010_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2010_label = pd.merge(P2010_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2010_label = pd.merge(P2010_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2010_label = pd.merge(P2010_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2010_label = pd.merge(P2010_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2010_label = pd.merge(P2010_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2010_label = pd.merge(P2010_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2010_label = P2010_label.fillna(0)\n",
    "sum(P2010_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110793.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2011_label = full_pair[full_pair.O==2011]\n",
    "P2011_label = pd.DataFrame({'P':list(set(P2011_label['P']))})\n",
    "P2011_label = pd.merge(P2011_label,cite_2012_df,how=\"left\",on=\"P\")\n",
    "P2011_label = pd.merge(P2011_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2011_label = pd.merge(P2011_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2011_label = pd.merge(P2011_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2011_label = pd.merge(P2011_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2011_label = pd.merge(P2011_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2011_label = pd.merge(P2011_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2011_label = P2011_label.fillna(0)\n",
    "sum(P2011_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121788.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2012_label = full_pair[full_pair.O==2012]\n",
    "P2012_label = pd.DataFrame({'P':list(set(P2012_label['P']))})\n",
    "P2012_label = pd.merge(P2012_label,cite_2013_df,how=\"left\",on=\"P\")\n",
    "P2012_label = pd.merge(P2012_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2012_label = pd.merge(P2012_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2012_label = pd.merge(P2012_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2012_label = pd.merge(P2012_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2012_label = pd.merge(P2012_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2012_label = P2012_label.fillna(0)\n",
    "sum(P2012_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146077.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2013_label = full_pair[full_pair.O==2013]\n",
    "P2013_label = pd.DataFrame({'P':list(set(P2013_label['P']))})\n",
    "P2013_label = pd.merge(P2013_label,cite_2014_df,how=\"left\",on=\"P\")\n",
    "P2013_label = pd.merge(P2013_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2013_label = pd.merge(P2013_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2013_label = pd.merge(P2013_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2013_label = pd.merge(P2013_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2013_label = P2013_label.fillna(0)\n",
    "sum(P2013_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176307.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2014_label = full_pair[full_pair.O==2014]\n",
    "P2014_label = pd.DataFrame({'P':list(set(P2014_label['P']))})\n",
    "P2014_label = pd.merge(P2014_label,cite_2015_df,how=\"left\",on=\"P\")\n",
    "P2014_label = pd.merge(P2014_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2014_label = pd.merge(P2014_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2014_label = pd.merge(P2014_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2014_label = P2014_label.fillna(0)\n",
    "sum(P2014_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207064.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2015_label = full_pair[full_pair.O==2015]\n",
    "P2015_label = pd.DataFrame({'P':list(set(P2015_label['P']))})\n",
    "P2015_label = pd.merge(P2015_label,cite_2016_df,how=\"left\",on=\"P\")\n",
    "P2015_label = pd.merge(P2015_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2015_label = pd.merge(P2015_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2015_label = P2015_label.fillna(0)\n",
    "sum(P2015_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220603.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2016_label = full_pair[full_pair.O==2016]\n",
    "P2016_label = pd.DataFrame({'P':list(set(P2016_label['P']))})\n",
    "P2016_label = pd.merge(P2016_label,cite_2017_df,how=\"left\",on=\"P\")\n",
    "P2016_label = pd.merge(P2016_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2016_label = P2016_label.fillna(0)\n",
    "sum(P2016_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199645.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2017_label = full_pair[full_pair.O==2017]\n",
    "P2017_label = pd.DataFrame({'P':list(set(P2017_label['P']))})\n",
    "P2017_label = pd.merge(P2017_label,cite_2018_df,how=\"left\",on=\"P\")\n",
    "P2017_label = P2017_label.fillna(0)\n",
    "sum(P2017_label['citation_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = {\n",
    "                    'P2000_label':P2000_label,\n",
    "                    'P2001_label':P2001_label,\n",
    "                    'P2002_label':P2002_label,\n",
    "                    'P2003_label':P2003_label,\n",
    "                    'P2004_label':P2004_label,\n",
    "                    'P2005_label':P2005_label,\n",
    "                   'P2006_label':P2006_label,\n",
    "                   'P2007_label':P2007_label,\n",
    "                   'P2008_label':P2008_label,\n",
    "                   'P2009_label':P2009_label,\n",
    "                   'P2010_label':P2010_label,\n",
    "                   'P2011_label':P2011_label,\n",
    "                   'P2012_label':P2012_label,\n",
    "                   'P2013_label':P2013_label,\n",
    "                   'P2014_label':P2014_label,\n",
    "                   'P2015_label':P2015_label,\n",
    "                   'P2016_label':P2016_label,\n",
    "                   'P2017_label':P2017_label\n",
    "                  }\n",
    "with open ('../data/original_labels.pkl','wb') as f:\n",
    "    pkl.dump(original_labels,f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative(df):\n",
    "    colsn = list(df.columns)\n",
    "    cols = df.shape[1]\n",
    "    for i in range(2,cols):\n",
    "        df[colsn[i]] = df[colsn[i]] + df[colsn[i-1]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2005_label = cumulative(P2005_label)\n",
    "P2006_label = cumulative(P2006_label)\n",
    "P2007_label = cumulative(P2007_label)\n",
    "P2008_label = cumulative(P2008_label)\n",
    "P2009_label = cumulative(P2009_label)\n",
    "P2010_label = cumulative(P2010_label)\n",
    "P2011_label = cumulative(P2011_label)\n",
    "P2012_label = cumulative(P2012_label)\n",
    "P2013_label = cumulative(P2013_label)\n",
    "P2014_label = cumulative(P2014_label)\n",
    "P2015_label = cumulative(P2015_label)\n",
    "P2016_label = cumulative(P2016_label)\n",
    "P2017_label = cumulative(P2017_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_labels = {'P2005_label':P2005_label,\n",
    "                   'P2006_label':P2006_label,\n",
    "                   'P2007_label':P2007_label,\n",
    "                   'P2008_label':P2008_label,\n",
    "                   'P2009_label':P2009_label,\n",
    "                   'P2010_label':P2010_label,\n",
    "                   'P2011_label':P2011_label,\n",
    "                   'P2012_label':P2012_label,\n",
    "                   'P2013_label':P2013_label,\n",
    "                   'P2014_label':P2014_label,\n",
    "                   'P2015_label':P2015_label,\n",
    "                   'P2016_label':P2016_label,\n",
    "                   'P2017_label':P2017_label\n",
    "                  }\n",
    "with open ('../data/cumulative_labels.pkl','wb') as f:\n",
    "    pkl.dump(cumulative_labels,f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P2005_label.iloc[:,1:] = np.log(P2005_label.iloc[:,1:]+1)\n",
    "P2006_label.iloc[:,1:] = np.log(P2006_label.iloc[:,1:]+1)\n",
    "P2007_label.iloc[:,1:] = np.log(P2007_label.iloc[:,1:]+1)\n",
    "P2008_label.iloc[:,1:] = np.log(P2008_label.iloc[:,1:]+1)\n",
    "P2009_label.iloc[:,1:] = np.log(P2009_label.iloc[:,1:]+1)\n",
    "P2010_label.iloc[:,1:] = np.log(P2010_label.iloc[:,1:]+1)\n",
    "P2011_label.iloc[:,1:] = np.log(P2011_label.iloc[:,1:]+1)\n",
    "P2012_label.iloc[:,1:] = np.log(P2012_label.iloc[:,1:]+1)\n",
    "P2013_label.iloc[:,1:] = np.log(P2013_label.iloc[:,1:]+1)\n",
    "P2014_label.iloc[:,1:] = np.log(P2014_label.iloc[:,1:]+1)\n",
    "P2015_label.iloc[:,1:] = np.log(P2015_label.iloc[:,1:]+1)\n",
    "P2016_label.iloc[:,1:] = np.log(P2016_label.iloc[:,1:]+1)\n",
    "P2017_label.iloc[:,1:] = np.log(P2017_label.iloc[:,1:]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_labels = {'P2005_label':P2005_label,\n",
    "                   'P2006_label':P2006_label,\n",
    "                   'P2007_label':P2007_label,\n",
    "                   'P2008_label':P2008_label,\n",
    "                   'P2009_label':P2009_label,\n",
    "                   'P2010_label':P2010_label,\n",
    "                   'P2011_label':P2011_label,\n",
    "                   'P2012_label':P2012_label,\n",
    "                   'P2013_label':P2013_label,\n",
    "                   'P2014_label':P2014_label,\n",
    "                   'P2015_label':P2015_label,\n",
    "                   'P2016_label':P2016_label,\n",
    "                   'P2017_label':P2017_label\n",
    "                  }\n",
    "with open ('../data/log_labels.pkl','wb') as f:\n",
    "    pkl.dump(log_labels,f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2005_label = cumulative(P2005_label)\n",
    "P2006_label = cumulative(P2006_label)\n",
    "P2007_label = cumulative(P2007_label)\n",
    "P2008_label = cumulative(P2008_label)\n",
    "P2009_label = cumulative(P2009_label)\n",
    "P2010_label = cumulative(P2010_label)\n",
    "P2011_label = cumulative(P2011_label)\n",
    "P2012_label = cumulative(P2012_label)\n",
    "P2013_label = cumulative(P2013_label)\n",
    "P2014_label = cumulative(P2014_label)\n",
    "P2015_label = cumulative(P2015_label)\n",
    "P2016_label = cumulative(P2016_label)\n",
    "P2017_label = cumulative(P2017_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_log_labels = {'P2005_label':P2005_label,\n",
    "                   'P2006_label':P2006_label,\n",
    "                   'P2007_label':P2007_label,\n",
    "                   'P2008_label':P2008_label,\n",
    "                   'P2009_label':P2009_label,\n",
    "                   'P2010_label':P2010_label,\n",
    "                   'P2011_label':P2011_label,\n",
    "                   'P2012_label':P2012_label,\n",
    "                   'P2013_label':P2013_label,\n",
    "                   'P2014_label':P2014_label,\n",
    "                   'P2015_label':P2015_label,\n",
    "                   'P2016_label':P2016_label,\n",
    "                   'P2017_label':P2017_label\n",
    "                  }\n",
    "with open ('../data/cumulative_log_labels.pkl','wb') as f:\n",
    "    pkl.dump(cumulative_log_labels,f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
